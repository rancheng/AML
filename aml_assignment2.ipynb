{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COMP 551 AML Assignment 2\n",
    "## Ran Cheng, 260768706\n",
    "This project is for assignment 2 of applied machine learning course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3\n",
      " 1.3 1.3] [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# read classifier data, mean\n",
    "ds1_m0_data = pd.read_csv('./Data/DS1_m_0.txt', sep=\",\", header=None)\n",
    "ds1_m0_data = ds1_m0_data.dropna(axis=1, how='all')\n",
    "ds1_m0 = np.squeeze(np.asarray(ds1_m0_data))\n",
    "ds1_m1_data = pd.read_csv('./Data/DS1_m_1.txt', sep=\",\", header=None)\n",
    "ds1_m1_data = ds1_m1_data.dropna(axis=1, how='all')\n",
    "ds1_m1 = np.squeeze(np.asarray(ds1_m1_data))\n",
    "print(ds1_m0, ds1_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read covarience matrrix\n",
    "ds1_cov_data = pd.read_csv('./Data/DS1_Cov.txt', sep=\",\", header=None)\n",
    "ds1_cov_data = ds1_cov_data.dropna(axis=1, how='all')\n",
    "ds1_cov = np.squeeze(np.asarray(ds1_cov_data))\n",
    "ds1_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22670522  1.11875031  2.10584674  0.42686339 -0.38069006  2.31383079\n",
      "  2.94942502  2.60081352  1.75815284  5.35586347  1.36733279  1.03294138\n",
      "  0.89712872  0.5713176   1.40034432  3.88254911 -0.36160315  1.90975477\n",
      "  0.11680028  0.74042753  0.        ] [-0.16501258 -0.27942621 -1.16703488 -0.99159389 -1.20104302 -0.8192157\n",
      "  0.86858126  0.69181763  1.28661494 -1.10579824  0.46289595  0.82346982\n",
      " -1.47932827 -0.78399104 -1.06281244  0.1551596   0.63767731 -0.44418858\n",
      "  0.99120889 -2.55542526  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the data for classifier, 0\n",
    "out_0 = np.random.multivariate_normal(ds1_m0, ds1_cov, size=2000)\n",
    "label_0 = np.zeros((2000,1))\n",
    "labeled_ds1_0 = np.hstack((out_0, label_0))\n",
    "# get the data for classifier, 1\n",
    "out_1 = np.random.multivariate_normal(ds1_m1, ds1_cov, size=2000)\n",
    "label_1 = np.ones((2000,1))\n",
    "labeled_ds1_1 = np.hstack((out_1, label_1))\n",
    "print(labeled_ds1_0[0], labeled_ds1_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaternate negative and positive data\n",
    "merged_ds1 = np.vstack((labeled_ds1_0,labeled_ds1_1))\n",
    "# shuffle the negative and positive data\n",
    "np.random.shuffle(merged_ds1)\n",
    "# get the data split into two parts randomly: training and testing data\n",
    "train, test = train_test_split(merged_ds1, test_size=0.3)\n",
    "n = train.shape[0]\n",
    "n_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu1 = np.mean(train[train[0:,-1] == 1][0:,0:-1], axis=0) #mu1 hat\n",
    "mu0 = np.mean(train[train[0:,-1] == 0][0:,0:-1], axis=0) #mu1 hat\n",
    "mu0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_0:  1403,  n_1:  1397\n"
     ]
    }
   ],
   "source": [
    "n_0 = len(train[train[0:,-1] == 0])\n",
    "n_1 = len(train[train[0:,-1] == 1])\n",
    "p_y0 = n_0/n\n",
    "p_y1 = n_1/n\n",
    "print('n_0: % d,' % n_0, ' n_1: % d' % n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = train[train[0:,-1] == 1][0:, 0:-1] - mu1\n",
    "sig1 =  np.dot(s1.transpose(), s1)\n",
    "s0 = train[train[0:,-1] == 1][0:, 0:-1] - mu0\n",
    "sig0 =  np.dot(s0.transpose(), s0)\n",
    "sigma = (sig0 + sig1)/n\n",
    "invsig = np.linalg.inv(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.012836542242569 (20,)\n"
     ]
    }
   ],
   "source": [
    "# estimate w0 and w1\n",
    "w_0 = np.log(p_y0) - np.log(p_y1) - (1/2)*(np.dot(np.dot(mu0.transpose(), invsig), mu0)) + (1/2)*(np.dot(np.dot(mu1.transpose(), invsig), mu1))\n",
    "w_1 = np.dot(invsig, (mu0 - mu1))\n",
    "print(w_0, w_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate of the estimation on the testing set is 58/1200 or : 4.833333333333333%\n"
     ]
    }
   ],
   "source": [
    "tmp = np.dot(test[0:,0:-1], w_1)\n",
    "result = w_0 + tmp\n",
    "result[result >= 0] = 0\n",
    "result[result < 0] = 1\n",
    "error = sum(result != test[:,-1])\n",
    "print(\"The error rate of the estimation on the testing set is {0}/{1} or : {2}%\"\\\n",
    "          .format(error, n_test, 100*error/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
