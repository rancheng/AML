{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COMP 551 AML Assignment 2\n",
    "## Ran Cheng, 260768706\n",
    "This project is for assignment 2 of applied machine learning course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3\n",
      " 1.3 1.3] [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# read classifier data, mean\n",
    "ds1_m0_data = pd.read_csv('./Data/DS1_m_0.txt', sep=\",\", header=None)\n",
    "ds1_m0_data = ds1_m0_data.dropna(axis=1, how='all')\n",
    "ds1_m0 = np.squeeze(np.asarray(ds1_m0_data))\n",
    "ds1_m1_data = pd.read_csv('./Data/DS1_m_1.txt', sep=\",\", header=None)\n",
    "ds1_m1_data = ds1_m1_data.dropna(axis=1, how='all')\n",
    "ds1_m1 = np.squeeze(np.asarray(ds1_m1_data))\n",
    "print(ds1_m0, ds1_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read covarience matrrix\n",
    "ds1_cov_data = pd.read_csv('./Data/DS1_Cov.txt', sep=\",\", header=None)\n",
    "ds1_cov_data = ds1_cov_data.dropna(axis=1, how='all')\n",
    "ds1_cov = np.squeeze(np.asarray(ds1_cov_data))\n",
    "ds1_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.85711382 3.27082293 4.83911834 4.21081536 4.47826915 3.8221002\n",
      " 4.1336902  5.45033372 4.19258166 4.63360667 3.92537702 5.68996287\n",
      " 4.98333053 5.34935994 2.9530259  4.34711386 5.54362476 5.28501803\n",
      " 4.81541228 3.21519516 0.        ] [5.19419541 1.24866164 4.7988989  3.63710792 4.43257475 3.93123032\n",
      " 2.69818007 3.90252446 5.55948964 6.20628212 5.04498428 2.23775316\n",
      " 4.37495695 4.74535528 5.70678508 7.23980291 3.80425261 3.92740907\n",
      " 1.59046353 4.85763864 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the data for classifier, 0\n",
    "out_0 = np.random.multivariate_normal(ds1_m0, ds1_cov, size=2000)\n",
    "label_0 = np.zeros((2000,1))\n",
    "labeled_ds1_0 = np.hstack((out_0, label_0))\n",
    "# get the data for classifier, 1\n",
    "out_1 = np.random.multivariate_normal(ds1_m1, ds1_cov, size=2000)\n",
    "label_1 = np.ones((2000,1))\n",
    "labeled_ds1_1 = np.hstack((out_1, label_1))\n",
    "print(labeled_ds1_0[0], labeled_ds1_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaternate negative and positive data\n",
    "merged_ds1 = np.vstack((labeled_ds1_0,labeled_ds1_1))\n",
    "# shuffle the negative and positive data\n",
    "np.random.shuffle(merged_ds1)\n",
    "# get the data split into two parts randomly: training and testing data\n",
    "train, test = train_test_split(merged_ds1, test_size=0.3)\n",
    "n = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu1 = np.mean(train[train[0:,-1] == 1][0:,0:-1], axis=0) #mu1 hat\n",
    "mu0 = np.mean(train[train[0:,-1] == 0][0:,0:-1], axis=0) #mu1 hat\n",
    "mu0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_0:  1420,  n_1:  1380\n"
     ]
    }
   ],
   "source": [
    "n_0 = len(train[train[0:,-1] == 0])\n",
    "n_1 = len(train[train[0:,-1] == 1])\n",
    "p_y0 = n_0/n\n",
    "p_y1 = n_1/n\n",
    "print('n_0: % d,' % n_0, ' n_1: % d' % n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = train[train[0:,-1] == 1][0:, 0:-1] - mu1\n",
    "sig1 =  np.dot(s1.transpose(), s1)\n",
    "s0 = train[train[0:,-1] == 1][0:, 0:-1] - mu0\n",
    "sig0 =  np.dot(s0.transpose(), s0)\n",
    "sigma = (sig0 + sig1)/n\n",
    "invsig = np.linalg.inv(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20) (20, 20)\n"
     ]
    }
   ],
   "source": [
    "# estimate w0 and w1\n",
    "w_0 = np.log(p_y0) - np.log(p_y1) - 1/2*(mu0.transpose() * invsig * mu0) + 1/2*(mu1.transpose() * invsig * mu1)\n",
    "w_1 = invsig * (mu0 - mu1)\n",
    "print(w_0.shape, w_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
