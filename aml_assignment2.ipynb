{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COMP 551 AML Assignment 2\n",
    "## Ran Cheng, 260768706\n",
    "This project is for assignment 2 of applied machine learning course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3\n",
      " 1.3 1.3] [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# read classifier data, mean\n",
    "ds1_m0_data = pd.read_csv('./Data/DS1_m_0.txt', sep=\",\", header=None)\n",
    "ds1_m0_data = ds1_m0_data.dropna(axis=1, how='all')\n",
    "ds1_m0 = np.squeeze(np.asarray(ds1_m0_data))\n",
    "ds1_m1_data = pd.read_csv('./Data/DS1_m_1.txt', sep=\",\", header=None)\n",
    "ds1_m1_data = ds1_m1_data.dropna(axis=1, how='all')\n",
    "ds1_m1 = np.squeeze(np.asarray(ds1_m1_data))\n",
    "print(ds1_m0, ds1_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read covarience matrrix\n",
    "ds1_cov_data = pd.read_csv('./Data/DS1_Cov.txt', sep=\",\", header=None)\n",
    "ds1_cov_data = ds1_cov_data.dropna(axis=1, how='all')\n",
    "ds1_cov = np.squeeze(np.asarray(ds1_cov_data))\n",
    "ds1_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.14491196  1.53017126  1.71401632  3.54927498  2.07323979  1.87764833\n",
      "  2.32451662  2.73364386  2.39486848  2.91365673  2.76285416  3.39611582\n",
      "  3.96712059  1.43105483 -0.24021163  0.66680738  2.3041561   3.0002512\n",
      "  1.31557552  2.91083169  0.        ] [-3.15529136 -2.3136306  -5.20673933 -2.77839985 -2.99008919 -3.48616892\n",
      " -2.44907064 -2.55133267 -1.0388036  -1.02870932 -0.41038205 -2.75029332\n",
      " -3.72827684 -1.090578   -2.98097217 -3.20934366 -3.36349414 -3.28055173\n",
      " -1.72360436 -0.6979119   1.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the data for classifier, 0\n",
    "out_0 = np.random.multivariate_normal(ds1_m0, ds1_cov, size=2000)\n",
    "label_0 = np.zeros((2000,1))\n",
    "labeled_ds1_0 = np.hstack((out_0, label_0))\n",
    "# get the data for classifier, 1\n",
    "out_1 = np.random.multivariate_normal(ds1_m1, ds1_cov, size=2000)\n",
    "label_1 = np.ones((2000,1))\n",
    "labeled_ds1_1 = np.hstack((out_1, label_1))\n",
    "print(labeled_ds1_0[0], labeled_ds1_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaternate negative and positive data\n",
    "merged_ds1 = np.vstack((labeled_ds1_0,labeled_ds1_1))\n",
    "# shuffle the negative and positive data\n",
    "np.random.shuffle(merged_ds1)\n",
    "# get the data split into two parts randomly: training and testing data\n",
    "train, test = train_test_split(merged_ds1, test_size=0.3)\n",
    "n = train.shape[0]\n",
    "n_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu1 = np.mean(train[train[0:,-1] == 1][0:,0:-1], axis=0) #mu1 hat\n",
    "mu0 = np.mean(train[train[0:,-1] == 0][0:,0:-1], axis=0) #mu1 hat\n",
    "mu0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_0:  1424,  n_1:  1376\n"
     ]
    }
   ],
   "source": [
    "n_0 = len(train[train[0:,-1] == 0])\n",
    "n_1 = len(train[train[0:,-1] == 1])\n",
    "p_y0 = n_0/n\n",
    "p_y1 = n_1/n\n",
    "print('n_0: % d,' % n_0, ' n_1: % d' % n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = train[train[0:,-1] == 1][0:, 0:-1] - mu1\n",
    "sig1 =  np.dot(s1.transpose(), s1)\n",
    "s0 = train[train[0:,-1] == 1][0:, 0:-1] - mu0\n",
    "sig0 =  np.dot(s0.transpose(), s0)\n",
    "sigma = (sig0 + sig1)/n\n",
    "invsig = np.linalg.inv(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: 4.0919 w1:  [ 2.14051524 -1.27070647 -0.87450193 -0.45329787 -1.45965003 -0.6318571\n",
      "  2.55355408 -3.59993189 -4.35064918  1.35902226 -1.97149091 -1.83832722\n",
      "  2.34055644  1.97955225 -0.81823733  1.93790251  4.36248385 -1.00938253\n",
      " -0.1011214  -0.75919109]\n"
     ]
    }
   ],
   "source": [
    "# estimate w0 and w1\n",
    "w_0 = np.log(p_y0) - np.log(p_y1) - (1/2)*(np.dot(np.dot(mu0.transpose(), invsig), mu0)) + (1/2)*(np.dot(np.dot(mu1.transpose(), invsig), mu1))\n",
    "w_1 = np.dot(invsig, (mu0 - mu1))\n",
    "print('w0: %0.4f' % w_0, 'w1: ', w_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate of the estimation on the testing set is 56/1200 or : 4.666666666666667%\n"
     ]
    }
   ],
   "source": [
    "tmp = np.dot(test[0:,0:-1], w_1)\n",
    "result = w_0 + tmp\n",
    "result[result >= 0] = 0\n",
    "result[result < 0] = 1\n",
    "error = sum(result != test[:,-1])\n",
    "print(\"The error rate of the estimation on the testing set is {0}/{1} or : {2}%\"\\\n",
    "          .format(error, n_test, 100*error/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.95      0.95      0.95       576\n",
      "    class 1       0.95      0.96      0.96       624\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit metric\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = test[:,-1]\n",
    "y_pred = result\n",
    "print(classification_report(y_true, y_pred, target_names=['class 0', 'class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
